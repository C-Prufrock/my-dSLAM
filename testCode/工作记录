2018.12.01
运行ORBSLAM2,跑TUM的walking_person的数据集,
主要研究初始化失败的原因;
影响其失败的往往不是初始的匹配点过少,即nmatches<=100;
而是Initializer-initialize()函数中难以重建H或者F模型;

1.只画出匹配成功的特征点;
2.卡方检验来判定某一组匹配点是否满足计算的F模型或者H模型;得分为偏差越大,得分越少.

3.关于神经网络识别的想法;  草!!昨天记下的话给丢了.!!
识别动态物体的本质(假设识别除了所有的运动物体):
1)从运动状态构成的空间来看,该方法是从诸多运动状态中剔除无限多的运动状态来保留静态---某种特殊的状态.
2)利用迭代Ransac 根据特征点结算出的运动状态空间 进行分类. 事实上,当你进行ransac,获得的第一个结果就包含诸多静态特征点或者动态特征点
就说明该方法在实践中结果并不好.这是因为收到outliers,噪声的干扰,运动参数组成的流形事实上并非一个完好的曲面,而是有一定mean 和
covariance的 空间.
3)先利用图像中pixel-pixel的位置信息,深度信息(如果是RGBD或双目相机的话)进行聚类,在各个聚类的子空间中进行


4.研究了如何从ransac筛选出的匹配点中找到地图点,设定了相关约束
比如:对得到的R,T,符合该模型的点为好点. --- 投影误差与z值判定.
对好点检验其视差,过小则舍去.
取视差较大的那个的点作为R,T的视差代表,如果过小则舍去.
如果有两个R,T都满足好点与视差的要求:好点数量大于50或者N*0.9;视差大于设定的最小视差. 则舍去计算结果.

5)ORBSLAM的初始化,由于其从F,H矩阵中恢复R,T时,要求可成功三角化的点的数量必须是匹配数量的0.9,事实上,当图像中出现运动目标时,
且动态目标上成功匹配的特征点占据不可忽视的比率时, 设定的约束条件是很难达到的,因此很难初始化.
2是在track的过程中,由于一些特征点在视差不断增大的图像中会track lost,数目逐渐增多.如果参考关键帧中没有动态目标,后续帧中出现,
则会很快track lost.需要重定位,而动态目标的出现也会使的重定位的

2018.12.1

特征点匹配和光流法跟踪同样,都是数据关联的一种方法.

不同的是,一个跟踪的是图像的灰度极值,一个理论是可跟踪任意点,因此SVO采样的是随机初始化.

光流法通过先在前后两帧图像里分别建立一个固定大小窗口，然后找到让两个窗口间像素强度差的平方和最小的位移。然后将窗口内像素的移动近似为这样的位移向量.

然而实际上,一方面像素移动并不会这么简单,另一方面窗口内像素并不都是同样的移动方式,因此这样 的近似必然带来误差.

而现在的问题就是 如何去选择合适的窗口,或者特征点,从而获得最为精确的跟踪.KLT角点检测方法就是为了选择而一个合适跟踪的特征点,它认为一个好的特征点的定义就是能被好的跟踪.

一个想法是:为了保证图像的特征点是稳定的,可采用三帧关联的方法,即必须在三个帧中都能发现该特征点并匹配上的点才视为选择的特征点.


2018.12.2
思考该问题:
在相邻帧中,运动物体与精致物体的运动模式如果查的比较小,则